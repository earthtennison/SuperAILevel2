{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "สำเนาของ Wazzadu__Siamese_final_v0.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/earthtennison/SuperAILevel2/blob/main/AI_image_search_SiameseNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zu_rnOq-h8Y"
      },
      "source": [
        "# Import Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-4F1Epe-h8d"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw\n",
        "import random\n",
        "import urllib.request\n",
        "import io\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85lFH-bH-h8f"
      },
      "source": [
        "# Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2XxPlLBCPkk"
      },
      "source": [
        "!gdown --id xxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyn5O2ZJCaaz"
      },
      "source": [
        "!unzip \"/content/trainKeys.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDV67Or85sw1"
      },
      "source": [
        "path = \"/content/trainKeys\"\r\n",
        "for folder in os.listdir(path):\r\n",
        "  print(folder,len( os.listdir(os.path.join(path,folder))  ))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DoLEC1G08tF"
      },
      "source": [
        "#df\r\n",
        "!cd /content/&& gdown --id 1zb4vWj_YxMbKEEtBQ8zaNrVL5g9yC_e_ "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQO-FwUf1BxE"
      },
      "source": [
        "!cd /content/&& unzip '/content/wazzadu.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLk_e31cxFO2"
      },
      "source": [
        "cat = pd.read_csv(\"/content/dim_cat_subcat_tag_key.csv\")\r\n",
        "train_df = pd.read_csv(\"/content/train.csv\")\r\n",
        "test_df = pd.read_csv(\"/content/test-sample.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_6hNBMWbPTl"
      },
      "source": [
        "###train test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70QqS4BjGm1V"
      },
      "source": [
        "from tqdm.auto import tqdm\r\n",
        "from random import shuffle,sample\r\n",
        "\r\n",
        "base_dir = \"/content/trainKeys\"\r\n",
        "folder_list = [f for f in os.listdir(base_dir) if f[0]=='p']\r\n",
        "print( len(folder_list), \"categories found in the dataset\")\r\n",
        "\r\n",
        "# Train test split \r\n",
        "train_test_split = 0.8\r\n",
        "no_of_files_in_each_class = 100\r\n",
        "\r\n",
        "# Declare training array\r\n",
        "cat_list = []\r\n",
        "x = []\r\n",
        "y = []\r\n",
        "y_label = ''\r\n",
        "index = 0\r\n",
        "\r\n",
        "# Using just 100 images per category\r\n",
        "for folder_name in tqdm(folder_list, desc = 'folder'):\r\n",
        "    file_list = os.listdir(os.path.join(base_dir, folder_name))\r\n",
        "    temp=[]\r\n",
        "\r\n",
        "    #random\r\n",
        "    file_list_pick = sample(file_list,no_of_files_in_each_class)\r\n",
        "    for file_name in file_list_pick:\r\n",
        "        temp.append(index)\r\n",
        "        x.append(np.asarray(Image.open(os.path.join(base_dir, folder_name, file_name)).convert('RGB').resize((100, 100))))\r\n",
        "        y.append(str(folder_name))\r\n",
        "        index += 1\r\n",
        "    cat_list.append(temp)\r\n",
        "\r\n",
        "cat_list = np.asarray(cat_list)\r\n",
        "x = np.asarray(x).astype(float)/255.0\r\n",
        "y = np.asarray(y).astype(str)\r\n",
        "print('x, y shape',x.shape, y.shape, cat_list.shape)      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lqjg66T1D_fz"
      },
      "source": [
        "# group x\r\n",
        "x_group = []\r\n",
        "for i in range(0,len(folder_list)):\r\n",
        "  x_group.append(x[i*no_of_files_in_each_class:(i+1)*no_of_files_in_each_class])\r\n",
        "x_group = np.asarray(x_group)\r\n",
        "\r\n",
        "#group y\r\n",
        "y_group = np.unique(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtEjoqGeEWu7"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "train_size = int(len(folder_list) *0.8)\r\n",
        "test_size = len(folder_list) - train_size\r\n",
        "print(train_size, 'classes for training and', test_size, ' classes for testing')\r\n",
        "\r\n",
        "# Training Split\r\n",
        "x_train = x_group[:train_size]\r\n",
        "y_train = y[:train_size*no_of_files_in_each_class]\r\n",
        "cat_train = cat_list[:train_size*no_of_files_in_each_class]\r\n",
        "\r\n",
        "x_train_full = x[:train_size*no_of_files_in_each_class]\r\n",
        "x_test_full = x[train_size*no_of_files_in_each_class:]\r\n",
        "\r\n",
        "# Validation Split\r\n",
        "x_test = x_group[train_size:]\r\n",
        "y_test = y[train_size*no_of_files_in_each_class:]\r\n",
        "cat_test = cat_list[train_size*no_of_files_in_each_class:]\r\n",
        "\r\n",
        "print('X&Y shape of training data :',x_train.shape, 'and', y_train.shape, cat_train.shape)\r\n",
        "print('X&Y shape of testing data :' , x_test.shape, 'and', y_test.shape, cat_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-T1FtSvT-h8h"
      },
      "source": [
        "### Batch Generator\n",
        "Here the idea is to make usuable batches for training the network. We need to create parallel inputs for the $A$ and $B$ images where the output is the distance. Here we make the naive assumption that if images are in the same group the similarity is 1 otherwise it is 0.\n",
        "\n",
        "If we randomly selected all of the images we would likely end up with most images in different groups."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "bivQ2y2o-h8h"
      },
      "source": [
        "def gen_random_batch(in_groups, batch_halfsize = 8):\n",
        "    out_img_a, out_img_b, out_score = [], [], []\n",
        "    all_groups = list(range(len(in_groups)))\n",
        "    for match_group in [True, False]:\n",
        "        group_idx = np.random.choice(all_groups, size = batch_halfsize)\n",
        "        out_img_a += [in_groups[c_idx][np.random.choice(range(in_groups[c_idx].shape[0]))] for c_idx in group_idx]\n",
        "        if match_group:\n",
        "            b_group_idx = group_idx\n",
        "            out_score += [1]*batch_halfsize\n",
        "        else:\n",
        "            # anything but the same group\n",
        "            non_group_idx = [np.random.choice([i for i in all_groups if i!=c_idx]) for c_idx in group_idx] \n",
        "            b_group_idx = non_group_idx\n",
        "            out_score += [0]*batch_halfsize\n",
        "            \n",
        "        out_img_b += [in_groups[c_idx][np.random.choice(range(in_groups[c_idx].shape[0]))] for c_idx in b_group_idx]\n",
        "            \n",
        "    return np.stack(out_img_a,0), np.stack(out_img_b,0), np.stack(out_score,0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1a0BT_R-h8i"
      },
      "source": [
        "## Validate Data\n",
        "Here we make sure the generator is doing something sensible, we show the images and their similarity percentage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRh-X9h2-h8i"
      },
      "source": [
        "pv_a, pv_b, pv_sim = gen_random_batch(x_train, 3)\n",
        "fig, m_axs = plt.subplots(2, pv_a.shape[0], figsize = (12, 6))\n",
        "for c_a, c_b, c_d, (ax1, ax2) in zip(pv_a, pv_b, pv_sim, m_axs.T):\n",
        "    ax1.imshow(c_a)\n",
        "    ax1.set_title('Image A')\n",
        "    ax1.axis('off')\n",
        "    ax2.imshow(c_b)\n",
        "    ax2.set_title('Image B\\n Similarity: %3.0f%%' % (100*c_d))\n",
        "    ax2.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kd2UFVmi-h8j"
      },
      "source": [
        "# Feature Generation\n",
        "Here we make the feature generation network to process images into features. The network starts off randomly initialized and will be trained to generate useful vector features from input images (_hopefully_)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_V2XtMZI-h8j"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, BatchNormalization, MaxPool2D, Activation, Flatten, Dense, Dropout\n",
        "img_in = Input(shape = x_train.shape[2:], name = 'FeatureNet_ImageInput')\n",
        "n_layer = img_in\n",
        "for i in range(2):\n",
        "    n_layer = Conv2D(8*2**i, kernel_size = (3,3), activation = 'linear')(n_layer)\n",
        "    n_layer = BatchNormalization()(n_layer)\n",
        "    n_layer = Activation('relu')(n_layer)\n",
        "    n_layer = Conv2D(16*2**i, kernel_size = (3,3), activation = 'linear')(n_layer)\n",
        "    n_layer = BatchNormalization()(n_layer)\n",
        "    n_layer = Activation('relu')(n_layer)\n",
        "    n_layer = MaxPool2D((2,2))(n_layer)\n",
        "n_layer = Flatten()(n_layer)\n",
        "n_layer = Dense(32, activation = 'linear')(n_layer)\n",
        "n_layer = Dropout(0.5)(n_layer)\n",
        "n_layer = BatchNormalization()(n_layer)\n",
        "n_layer = Activation('relu')(n_layer)\n",
        "feature_model = Model(inputs = [img_in], outputs = [n_layer], name = 'FeatureGenerationModel')\n",
        "feature_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYQU3Hq1-h8j"
      },
      "source": [
        "# Siamese Model\n",
        "We apply the feature generating model to both images and then combine them together to predict if they are similar or not. The model is designed to very simple. The ultimate idea is when a new image is taken that a feature vector can be calculated for it using the _FeatureGenerationModel_. All existing images have been pre-calculated and stored in a database of feature vectors. The model can be applied using a few vector additions and multiplications to determine the most similar images. These operations can be implemented as a stored procedure or similar task inside the database itself since they do not require an entire deep learning framework to run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvCytnW6-h8k"
      },
      "source": [
        "from keras.layers import concatenate\n",
        "img_a_in = Input(shape = x_train.shape[2:], name = 'ImageA_Input')\n",
        "img_b_in = Input(shape = x_train.shape[2:], name = 'ImageB_Input')\n",
        "img_a_feat = feature_model(img_a_in)\n",
        "img_b_feat = feature_model(img_b_in)\n",
        "combined_features = concatenate([img_a_feat, img_b_feat], name = 'merge_features')\n",
        "combined_features = Dense(16, activation = 'linear')(combined_features)\n",
        "combined_features = BatchNormalization()(combined_features)\n",
        "combined_features = Activation('relu')(combined_features)\n",
        "combined_features = Dense(4, activation = 'linear')(combined_features)\n",
        "combined_features = BatchNormalization()(combined_features)\n",
        "combined_features = Activation('relu')(combined_features)\n",
        "combined_features = Dense(1, activation = 'sigmoid')(combined_features)\n",
        "similarity_model = Model(inputs = [img_a_in, img_b_in], outputs = [combined_features], name = 'Similarity_Model')\n",
        "similarity_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "CpXaStvY-h8l"
      },
      "source": [
        "# setup the optimization process\n",
        "similarity_model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics = ['mae'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9X6F0bMk-h8l"
      },
      "source": [
        "## Before train\n",
        "Here we visualize what the model does by taking a small sample of randomly selected A and B images the first half from the same category and the second from different categories. We then show the actual distance (0 for the same category and 1 for different categories) as well as the model predicted distance. The first run here is with a completely untrained network so we do not expect meaningful results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwPCUiRW-h8l"
      },
      "source": [
        "def show_model_output(nb_examples = 3):\n",
        "    pv_a, pv_b, pv_sim = gen_random_batch(x_test, nb_examples)\n",
        "    pred_sim = similarity_model.predict([pv_a, pv_b])\n",
        "    fig, m_axs = plt.subplots(2, pv_a.shape[0], figsize = (12, 6))\n",
        "    for c_a, c_b, c_d, p_d, (ax1, ax2) in zip(pv_a, pv_b, pv_sim, pred_sim, m_axs.T):\n",
        "        ax1.imshow(c_a[:,:,:])\n",
        "        ax1.set_title('Image A\\n Actual: %3.0f%%' % (100*c_d))\n",
        "        ax1.axis('off')\n",
        "        ax2.imshow(c_b[:,:,:])\n",
        "        ax2.set_title('Image B\\n Predicted: %3.0f%%' % (100*p_d))\n",
        "        ax2.axis('off')\n",
        "    return fig\n",
        "# a completely untrained model\n",
        "_ = show_model_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov1WX2sP-h8m"
      },
      "source": [
        "# make a generator out of the data\n",
        "def siam_gen(in_groups, batch_size = 64):\n",
        "    while True:\n",
        "        pv_a, pv_b, pv_sim = gen_random_batch(x_train, batch_size//2)\n",
        "        yield [pv_a, pv_b], pv_sim\n",
        "        \n",
        "# we want a constant validation group to have a frame of reference for model performance\n",
        "valid_a, valid_b, valid_sim = gen_random_batch(x_test, 1024)\n",
        "loss_history = similarity_model.fit_generator(siam_gen(x_train), \n",
        "                               steps_per_epoch = 500,\n",
        "                               validation_data=([valid_a, valid_b], valid_sim),\n",
        "                                              epochs = 50,\n",
        "                                             verbose = True)\n",
        "\n",
        "similarity_model.save('similarity_model_latest.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBJJrNe6jefD"
      },
      "source": [
        "###After train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hH3U3LsaQ53"
      },
      "source": [
        "_ = show_model_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vv8FcKok-h8n"
      },
      "source": [
        "#Prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlwZmIrsGoiJ"
      },
      "source": [
        "test_df = pd.read_csv(\"/content/test-sample.csv\")\r\n",
        "test_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiQP-XDRHKU8"
      },
      "source": [
        "def read_im(i):\r\n",
        "  # Display image \r\n",
        "  URL = test_df.url[i]\r\n",
        "\r\n",
        "  with urllib.request.urlopen(URL) as url:\r\n",
        "    f = io.BytesIO(url.read())\r\n",
        "  img = Image.open(f)\r\n",
        "\r\n",
        "  # Dimension\r\n",
        "  w, h = np.array(img).shape[1], np.array(img).shape[0]\r\n",
        "  shape = [(int(test_df.tl_x[i]*w), int(test_df.tl_y[i]*h)), (int(test_df.br_x[i]*w), int(test_df.br_y[i]*h))] \r\n",
        "\r\n",
        "  ip = img.crop((int(test_df.tl_x[i]*w), int(test_df.tl_y[i]*h), int(test_df.br_x[i]*w), int(test_df.br_y[i]*h)))\r\n",
        "  # display(ip)\r\n",
        "  ip = ip.convert('RGB').resize((100, 100))\r\n",
        "  ip = np.asarray(ip)/255.0\r\n",
        "  return ip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAr3ShN_QJPu"
      },
      "source": [
        "#test\r\n",
        "ip = read_im(0)\r\n",
        "plt.imshow(ip)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjO5S0-nR-fS"
      },
      "source": [
        "# similarity_model.load_weights('/content/weight/weights.3000.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sM7DHB5c3MZ"
      },
      "source": [
        "###x_group  and y_group"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQvnY3rB58Zl"
      },
      "source": [
        "x_test_submit = []\r\n",
        "submit = []\r\n",
        "x_test_submit.append(np.zeros((24, 100, 100, 3)))\r\n",
        "x_test_submit.append(np.zeros((24, 100, 100, 3)))\r\n",
        "for i in range(len(test_df)):\r\n",
        "  ip = read_im(i)\r\n",
        "  for j in range(24):\r\n",
        "    x_test_submit[0][j] = ip\r\n",
        "    index = random.randint(0,no_of_files_in_each_class-1)\r\n",
        "    x_test_submit[1][j] = x_group[j][index]\r\n",
        "\r\n",
        "  pred = similarity_model.predict(x_test_submit)\r\n",
        "  submit.append(y_group[np.argmax(pred)])\r\n",
        "  # print(pred)\r\n",
        "  # print(y_group[np.argmax(pred)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-P74PCLb-J6"
      },
      "source": [
        "submit_df = pd.DataFrame()\r\n",
        "submit_df['key']=submit\r\n",
        "submit_df.to_csv('machima_3.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "qlptAOtZ-h8o"
      },
      "source": [
        "#Examining the Features\n",
        "Here we aim to answer the more general question: did we generate useful features with the Feature Generation model? And how can we visualize this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "R5YFXJvS-h8o"
      },
      "source": [
        "x_test_features = feature_model.predict(x_test_full, verbose = True, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2WHEKb3-h8o"
      },
      "source": [
        "## Neighbor Visualization\n",
        "For this we use the TSNE neighborhood embedding to visualize the features on a 2D plane and see if it roughly corresponds to the groups. We use the test data for this example as well since the training has been contaminated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftxcCZGg-h8o",
        "scrolled": true
      },
      "source": [
        "%%time\n",
        "from sklearn.manifold import TSNE\n",
        "tsne_obj = TSNE(n_components=2,\n",
        "                         init='pca',\n",
        "                         random_state=101,\n",
        "                         method='barnes_hut',\n",
        "                         n_iter=500,\n",
        "                         verbose=2)\n",
        "tsne_features = tsne_obj.fit_transform(x_test_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "NibJ5t2_-h8p"
      },
      "source": [
        "obj_categories = y_group\n",
        "colors = plt.cm.rainbow(np.linspace(0, 1, 24))\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "for c_group, (c_color, c_label) in enumerate(zip(colors, obj_categories)):\n",
        "    plt.scatter(tsne_features[np.where(y_test == y_group[c_group]), 0],\n",
        "                tsne_features[np.where(y_test == y_group[c_group]), 1],\n",
        "                marker='o',\n",
        "                color=c_color,\n",
        "                linewidth='1',\n",
        "                alpha=0.8,\n",
        "                label=c_label)\n",
        "plt.xlabel('Dimension 1')\n",
        "plt.ylabel('Dimension 2')\n",
        "plt.title('t-SNE on Testing Samples')\n",
        "plt.legend(loc='best')\n",
        "plt.savefig('clothes-dist.png')\n",
        "plt.show(block=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "_3PRj6xK-h8p"
      },
      "source": [
        "similarity_model.save('similarity_model_latest.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}